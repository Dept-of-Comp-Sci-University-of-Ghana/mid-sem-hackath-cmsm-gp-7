{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install emoji\n"
      ],
      "metadata": {
        "id": "ESZCt093jMC5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing the neccessary libraries\n",
        "import tweepy\n",
        "from textblob import TextBlob\n",
        "from wordcloud import WordCloud\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "import emoji\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import spacy\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "plt.style.use('fivethirtyeight')"
      ],
      "metadata": {
        "id": "mIj_aVgf7C5M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assigning the LGBTQ dataset to a data object\n",
        "data = pd.read_csv('/content/drive/MyDrive/LGBTQ-Reduced.csv')\n",
        "data.head()\n",
        "\n",
        "# Storing the tweets in a dataframe\n",
        "df_lgbtq = pd.DataFrame(data['tweet'])\n",
        "print(df_lgbtq.head())"
      ],
      "metadata": {
        "id": "_UdfvgI7Ywfs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Developing a dictionary for shorthand texts\n",
        "# Send a GET request\n",
        "url = \"https://messente.com/blog/text-abbreviations\"\n",
        "response = requests.get(url)\n",
        "\n",
        "# Parse the HTML content using BeautifulSoup\n",
        "soup = BeautifulSoup(response.content, \"html.parser\")\n",
        "\n",
        "# Find the second and third b tags and extract the data\n",
        "b_tags = soup.find_all(\"b\")\n",
        "second_b_tag = b_tags[1]\n",
        "third_b_tag = b_tags[2]\n",
        "\n",
        "# Find all paragraphs inside the second and third b tags, excluding the first paragraph\n",
        "second_paragraphs = second_b_tag(\"p\")[1:]\n",
        "third_paragraphs = third_b_tag(\"p\")[1:]\n",
        "\n",
        "# Extract the slang words and descriptions\n",
        "slang_list = []\n",
        "description_list = []\n",
        "count = 0\n",
        "\n",
        "for paragraph in second_paragraphs + third_paragraphs:\n",
        "  if count <= 99:\n",
        "    split_text = paragraph.text.strip().split(\" â€“ \", 1)\n",
        "    slang = split_text[0].split(\". \", 1)[-1].lower()\n",
        "    description = split_text[1] if len(split_text) > 1 else \"\"\n",
        "    slang_list.append(slang)\n",
        "    description_list.append(description)\n",
        "    count += 1\n",
        "\n",
        "  else:\n",
        "    break\n",
        "\n",
        "# Create a DataFrame from the extracted data\n",
        "df_slangs = pd.DataFrame({\n",
        "    \"slang\": slang_list,\n",
        "    \"description\": description_list\n",
        "})\n",
        "\n",
        "# Print the DataFrame\n",
        "print(df_slangs)"
      ],
      "metadata": {
        "id": "xVW0TlyhrwPY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocessing the data\n",
        "\n",
        "# Developing a function to clean the data\n",
        "def clean_tweet(text):\n",
        "  text = re.sub(r'@[A-Za-z0-9]+', '', text) # removes mentions\n",
        "  text = re.sub(r'#', '', text) # removes hashtags\n",
        "  text = re.sub(r'RT[\\s]+', '', text) # removes retweets\n",
        "  text = re.sub(r'https?:\\/\\/\\S+', '', text) # removes hyperlinks\n",
        "  text = re.sub(r'\\.{2,}', '.', text) # removes repeated fullstops\n",
        "  text = re.sub(r'!{2,}', '!', text) # removes repeated exclammation marks\n",
        "  text = re.sub(r'\\?{2,}', '?', text) # removes repeated question marks\n",
        "  text = re.sub(r'\\s+', ' ', text) # removes extra space around text\n",
        "  text = emoji.demojize(text, delimiters=(\"\", \"\")) # replacing the emojis with respective labels\n",
        "\n",
        "  words = text.split() # splits text into each word\n",
        "  normalized_words = [df_slangs.loc[df_slangs['slang'] == word, \"description\"].values[0]\n",
        "    if word in df_slangs['slang'].values else word for word in words] # removes slangs\n",
        "  text = \" \".join(normalized_words)\n",
        "\n",
        "  return text.lower()\n",
        "\n",
        "# Cleaning the tweet\n",
        "df_lgbtq['tweet'] = df_lgbtq['tweet'].apply(clean_tweet)\n",
        "\n",
        "# Showing the prepocessed data\n",
        "df_lgbtq.head()"
      ],
      "metadata": {
        "id": "fCl7CmR7zTXv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lemmatization\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Function to lemmatize each word in a tweet\n",
        "def lemmatize_text(text):\n",
        "    doc = nlp(text)\n",
        "    lemmas = [token.lemma_ for token in doc]\n",
        "    return ' '.join(lemmas)\n",
        "\n",
        "# Apply lemmatization to the 'tweet' column\n",
        "df_lgbtq['tweet'] = df_lgbtq['tweet'].apply(lemmatize_text)\n",
        "\n",
        "print(df_lgbtq['tweet'])"
      ],
      "metadata": {
        "id": "fT56U9P8LlR7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Removing stopwords\n",
        "\n",
        "# Getting the current list of English stopwords\n",
        "stopword_list = stopwords.words('english')\n",
        "\n",
        "# Function to remove stopwords from tweet\n",
        "def remove_stopwords(text):\n",
        "    tokens = word_tokenize(text)\n",
        "    filtered_tokens = [token for token in tokens if token.lower() not in stopword_list]\n",
        "    text = ' '.join(filtered_tokens)\n",
        "    return text\n",
        "\n",
        "# Apply stopword removal to the 'tweet' column\n",
        "df_lgbtq['tweet'] = df_lgbtq['tweet'].apply(remove_stopwords)\n",
        "\n",
        "print(df_lgbtq)"
      ],
      "metadata": {
        "id": "lDbpPgxWczBN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting the subjectivity and polarity of tweets\n",
        "\n",
        "# creating a function to get subjectivity\n",
        "def getSubjectivity(text):\n",
        "  return TextBlob(text).sentiment.subjectivity\n",
        "\n",
        "# creating a function to get polarity\n",
        "def getPolarity(text):\n",
        "  return TextBlob(text).sentiment.polarity\n",
        "\n",
        "# adding subjectivity and polarity of tweets as columns to dataset\n",
        "df_lgbtq['Subjectivity'] = df_lgbtq['tweet'].apply(getSubjectivity)\n",
        "df_lgbtq['Polarity'] = df_lgbtq['tweet'].apply(getPolarity)\n",
        "\n",
        "# showing the dataset\n",
        "df_lgbtq"
      ],
      "metadata": {
        "id": "MC3OPlLhlIGO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting the Word Cloud\n",
        "words = ' '.join([tweets for tweets in df_lgbtq['tweet']])\n",
        "wordcloud = WordCloud(width=1000, height=300, random_state=21, background_color='white', max_font_size=200 ).generate(words)\n",
        "\n",
        "plt.imshow(wordcloud, interpolation='bilinear')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "hXUnwK-M_64h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to find negative, neutral and positive tweets\n",
        "def analyse(score):\n",
        "  if score < 0:\n",
        "    return 'Negative'\n",
        "  elif score == 0:\n",
        "    return 'Neutral'\n",
        "  else:\n",
        "    return 'Positive'\n",
        "\n",
        "df_lgbtq['Analysis'] = df_lgbtq['Polarity'].apply(analyse)\n",
        "\n",
        "df_lgbtq"
      ],
      "metadata": {
        "id": "gsA4rpUlDEbH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Finding all positive tweets\n",
        "q=1\n",
        "lgbtq_sorted = df_lgbtq.sort_values(by=['Polarity'])\n",
        "for l in range(0, lgbtq_sorted.shape[0]):\n",
        "  if(lgbtq_sorted['Analysis'][l] == 'Positive'):\n",
        "    print(str(q) + ') ' + lgbtq_sorted['tweet'][l])\n",
        "    print()\n",
        "    q = q+1"
      ],
      "metadata": {
        "id": "mSIverbcEly_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Finding all negative tweets\n",
        "q=1\n",
        "lgbtq_sorted = df_lgbtq.sort_values(by=['Polarity'], ascending=False)\n",
        "for l in range(0, lgbtq_sorted.shape[0]):\n",
        "  if(lgbtq_sorted['Analysis'][l] == 'Negative'):\n",
        "    print(str(q) + ') ' + lgbtq_sorted['tweet'][l])\n",
        "    print()\n",
        "    q = q+1"
      ],
      "metadata": {
        "id": "Zjd1sJsxGaq9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting a graph of polarity and subjectivity\n",
        "plt.figure(figsize=(10,8))\n",
        "for i in range(0, df_lgbtq.shape[0]):\n",
        "  plt.scatter(df_lgbtq['Polarity'][i], df_lgbtq['Subjectivity'][i], color='Red')\n",
        "\n",
        "plt.title('Sentiment Analysis of LGBTQ Tweets')\n",
        "plt.xlabel('Polarity')\n",
        "plt.ylabel('Subjectivity')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "k_WNois4Hnsd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting percentage of positive and negative tweets\n",
        "\n",
        "# positive tweets\n",
        "p_tweets = df_lgbtq[df_lgbtq.Analysis == 'Positive']\n",
        "p_tweets = p_tweets['tweet']\n",
        "\n",
        "round( (p_tweets.shape[0] / df_lgbtq.shape[0]) * 100, 1)"
      ],
      "metadata": {
        "id": "trXw-G_8RsoD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# negative tweets\n",
        "n_tweets = df_lgbtq[df_lgbtq.Analysis == 'Negative']\n",
        "n_tweets = n_tweets['tweet']\n",
        "\n",
        "round( (n_tweets.shape[0] / df_lgbtq.shape[0]) * 100, 1)"
      ],
      "metadata": {
        "id": "iFXk4AKDXL0Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Value Counts\n",
        "\n",
        "df_lgbtq['Analysis'].value_counts()\n",
        "\n",
        "# plot and visualize the counts\n",
        "plt.title('Sentiment Analysis')\n",
        "plt.xlabel('Sentiment')\n",
        "plt.ylabel('Counts')\n",
        "df_lgbtq['Analysis'].value_counts().plot(kind='bar')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "BupJ9kBsXeWA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shutil.make_archive('/content/html_docs', 'zip', '/content/_build/html')\n",
        "files.download('/content/html_docs.zip')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "nrDpzqP8NVaG",
        "outputId": "14390efa-301d-4a3f-d42f-34485aa79eb8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_30a16584-8014-49af-9da1-b3af859293bb\", \"html_docs.zip\", 22)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}